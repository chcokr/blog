# Thoughts on Programming Languages (Part 1 — Types, Null)

2014 was a hell of a year for many reasons, and one of them is that it marks the
ten-year anniversary of the anecdote on my LinkedIn profile:

```Text
When I first started self-teaching programming in middle school, my parents, who
had not been familiar with the idea of computer programming, told me to stop
wasting time on computers.
```

Since then, I have used a few programming languages.
In the process of learning these languages, I have noticed some upsides and
downsides of each, and naturally started developing opinions towards or against
certain features in languages.
In this series I would like to share these thoughts, on what I perceive as good
or bad features.

## Static or Dynamic

Before I start, I would like to share thoughts on the static vs dynamic typing.
I've seen people who get nauseated by JavaScript's dynamica nature, for example.
Me, I am of the opinion that both sides really have their unique use cases;
neither should be looked down upon.

I’d like to provide an example from this past weekend.
I started hacking together a Rust-to-JavaScript transpiler in Rust (I’m aware
I’m not the only one who’s tried this).
In order to build a JS abstract syntax tree, I needed to abide by a JS AST
protocol.
If I were writing this transpiler in JavaScript, I would simply build a big JSON
object of the following sort, and then feed it into Escodegen to generate actual
JavaScript.

```JSON
{
    "type": "Program",
    "body": [
        {
            "type": "VariableDeclaration",
            "declarations": [
                {
                    "type": "VariableDeclarator",
                    "id": {
                        "type": "Identifier",
                        "name": "x"
                    },
                    "init": {
                        "type": "Literal",
                        "value": 1,
                        "raw": "1"
                    }
                }
            ],
            "kind": "var"
        }
    ]
}
```

There’s no need to create any boilerplate in order to generate this JSON: just
create a plain old JS object that looks alike.
Now, since I’m writing this transpiler in Rust, life can’t be this simple.
I’d be better off creating a whole bunch of structs mocking the Parser API, such
as the following example.

```Rust
pub enum Pattern<'a> {
  Expression(Expression<'a>),
  ObjectPattern(ObjectPattern<'a>),
  ArrayPattern(ArrayPattern<'a>)
}
```

In the end, it took me more than a thousand lines of additional boilerplate
mocking the Parser API, just to even get started on building the transpiler.

But does this extra labor come at no advantage?
It certainly comes at a very strong advantage; for example, with Rust’s powerful
match statements, I can make sure I don’t leave out logical grey areas in my
code, by checking all variant of my enum are covered, etc.
I would favor such logical rigor when I’m writing a compiler/transpiler.
I get a strong feeling that, had I written this program in JavaScript, it would
have initially been filled with a multitude of errors I would only discover
later into the hacking phase.

Am I saying I would never be able to discover such errors?
Of course not (after all, tools like Esprima and Escodegen do a killer job of
carrying out some logic-heavy tasks in JavaScript).
There’s a reason we write tests; tests should exist for both statically and
dynamically typed codes.
Such tests would figure out what’s going wrong with my code fairly easily.
The issue here is not that errors can’t be discovered — it is that they are
discovered at a later time, and as such, the cost of debugging has probably
increased.

I somewhat disagree with the notion that static typing eliminates errors.
A spec and a corresponding test should determine what is an error, not a bunch
of types.
What static typing can do is preventing errors earlier.
For scenarios with complex logic, this can be a huge deal — depending on
preferences.

I also disagree with the idea that dynamic typing sucks because it is confusing
to pass what arguments into what functions, etc.
With good documentation, this shouldn’t even be an issue.
Well, OK, there are situations where we don’t have enough time to write full
blobs of documentation.
But for a significant part of the time, it’s often so common to easily deduce
whether a string or an int should be passed into some utility function,
especially when there are only few members working on the code base.
If this wasn’t the case, the entire NPM ecosystem would have been in danger.

In the meantime, static typing could bring about other advantages such as
performance optimizations according to types, but I won’t go further.

So yes, I decline to take side on this matter.
Software is meant to solve problems.
It’s like navigating in the ocean.
Types are like flashing lighthouses — they definitely help, especially when it’s
dark.
Meanwhile, there are other tools too, like compasses, maps, navigational
knowledge, etc.
If these other tools are enough to get the ship to the destination, then why
build the expensive lighthouses?

So let’s move on to language features.

## The Curse of Null

I have had so much beef with the null type that this had to be the first one.
Sure, there are code quality tools (such as Facebook’s impressive Flow type
checker) that detect these erroneous cases, but they sometimes come across
null-related errors that are extremely hard to track down, and these are
troublesome.
[Eric Kidd](http://www.randomhacks.net/2014/09/19/rust-lifetimes-reckless-cxx/)
brought up a good example of a segfault occuring against an intuitive line of
code in C++.
Or check out this [Quora
anecdote](https://www.quora.com/University-of-California-Berkeley-1/What-are-some-instances-of-Paul-Hilfingers-notoriety/answer/Arun-Vijayvergiya)
about having some fun with a dangling null in a compiler.

I wouldn’t say the reason behind all these disasters is null itself.
The issue is people — people forget to handle null; they then get struck with
some random `NullPointerException` later into development, at a probably
increased debugging cost.
Since there are so many dynamic edge cases against `null`, `null` gets smudged
underneath the awesome rest of the logic, simply because the grammar does not
explicitly shed light on the edge cases.
I’m not blaming anyone here; people make mistakes, as long as the programming
language doesn’t stop them from doing so.

One day I was eagerly writing some code fetching data from AWS DynamoDB, whose
JavaScript SDK involves a lot of expressions like this:
`data.Responses.table1[0].attr1.SS[0]`.
Since I was so in the zone, I of course forgot to care about which one of the
six parents might be null.
And guess what happened — I got a TypeError there.
Shit.
Which of the six is null?!

Well, to be fair, if the intent of that line was to see whether that whole line
evaluated to null or not, I could simply use `lodash-contrib`’s `_.getPath()` or
something along the lines to evaluate the whole thing as null.
But in other situations where the stage at which null occurs is important or
null shouldn’t occur at all to begin with, a rough debugging session would
ensue.

An argument toward null is that it captures the intuitive notion of nothingness.
I agree.
Nothingness is a concept that’s been around for so long that it’s nice to have.
However, nothingness does not necessarily have to appear in the form of a
special type producing hundreds of edge cases — not even statically, but
dynamically during runtime.
Why not have nothingness appear in a statically forced, syntactically
identifiable form leaving little to no grey area?
Let’s take a look at Rust’s `std::Option<T>` type.
I heard Haskell and many other functional languages have something similar.

```Rust
fn foo(x: Option<int>) {
    match x {
        Some(val) -> println!("{}", val),
        None -> println!("Sad")
    }
}
```

This function `foo` takes in an argument which could be an integer or just
nothing.
Here, nothingness isn't represented as a null.
Then in the function body, we’re saying: if the argument is an integer value,
print out the value; if not, print out "Sad."
All this was achievable without leaving any grey area potentially caused by
`null`.
The exhaustive match clause ensures all logical branches are covered, and nobody
would dare try to access a property on `x`, because the compiler would complain
(well, to be fair, an int has no properties to begin with, but you get my
point).

I remember when I was studying math, my professor emphasized the importance of
"reading between the lines."
There’s a lot of insight going on between those lines in our math textbooks, and
it is the student’s responsibility to suck in all that through countless hours
of effort, frustration and epiphany.

The same does not apply to programming languages.
Software should be written in a manner that is not only concise, but also
plainly explicit so that the reader doesn’t have to try hard to figure out the
next chance to fire the writer of the bad code.
Writing software is stressful, but reading it is also as burdensome, if not
more.
Let’s take some stress off of our minds.
It’s good to be ***explicit***.
